{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO5plFRBSVk+OdcVa10CGw/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jshajbc/1122/blob/main/Unet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "qawIxpEfIPFc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import random\n",
        "import cv2\n",
        "from random import shuffle\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from glob import glob\n",
        "from os.path import splitext\n",
        "from os import listdir\n",
        "import os\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\") # mount your Google Drive; allow the notebook to access the data in your google drive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jaRaVly2IZOY",
        "outputId": "c68495e0-851e-41fd-a0f7-4fea906ff22d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = \"/content/drive/My Drive/unet/\" # in-drive data path\n",
        "\n",
        "os.chdir(dataset_path)\n",
        "os.listdir(dataset_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOJFQ5m_IhrO",
        "outputId": "dff639d4-d61b-4aa3-f742-b35e233b9686"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ori_data', 'ckpts', 'resample', 'dst']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install pillow numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2ijvMHYYBZg",
        "outputId": "17fb0cad-0904-4920-83ac-205f2eccef3a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (9.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "# 设置数据路径\n",
        "dataset_path = \"/content/drive/My Drive/unet/ori_data/\"\n",
        "\n",
        "def tiff_to_npy(tiff_path, npy_path):\n",
        "    with Image.open(tiff_path) as img:\n",
        "        image_array = np.array(img)\n",
        "    np.save(npy_path, image_array)\n",
        "    print(f\"Saved {npy_path}\")\n",
        "\n",
        "# 遍历指定文件夹，找到所有.tif文件\n",
        "for filename in os.listdir(dataset_path):\n",
        "    if filename.endswith(\".png\"):  # 确保只处理.tif文件\n",
        "        full_tiff_path = os.path.join(dataset_path, filename)\n",
        "        npy_filename = filename.replace('.png', '.npy')\n",
        "        full_npy_path = os.path.join(dataset_path, npy_filename)\n",
        "\n",
        "        # 调用函数进行转换\n",
        "        tiff_to_npy(full_tiff_path, full_npy_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hotvSzLOYSss",
        "outputId": "df5bba0e-0a93-4461-dd62-8d0ec1903eb0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved /content/drive/My Drive/unet/ori_data/img.npy\n",
            "Saved /content/drive/My Drive/unet/ori_data/label.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import tqdm\n",
        "\n",
        "def load_image(input_path, target_path):\n",
        "    image = np.load(input_path)\n",
        "    print('image.shape: ', image.shape)\n",
        "    label = np.load(target_path)\n",
        "    print('label.shape: ', label.shape, np.unique(label))\n",
        "    return image, label\n",
        "\n",
        "input_dir = './ori_data/img.npy'\n",
        "target_dir = './ori_data/label.npy'\n",
        "image, label = load_image(input_dir, target_dir)\n",
        "\n",
        "img_save_dir = './resample/{}/src/'.format('train')\n",
        "target_save_dir = './resample/{}/label/'.format('train')\n",
        "valid_img_save_dir = './resample/{}/src/'.format('valid')\n",
        "valid_target_save_dir = './resample/{}/label/'.format('valid')\n",
        "\n",
        "os.makedirs(img_save_dir, exist_ok=True)\n",
        "os.makedirs(target_save_dir, exist_ok=True)\n",
        "os.makedirs(valid_img_save_dir, exist_ok=True)\n",
        "os.makedirs(valid_target_save_dir, exist_ok=True)\n",
        "\n",
        "sub_sampling_num = 500\n",
        "x_crop = 256\n",
        "y_crop = 256\n",
        "\n",
        "valid_ratio = 0.2\n",
        "train_valid_count = {'train samples: ':0, 'valid samples: ':0}\n",
        "\n",
        "for i in tqdm.tqdm(range(sub_sampling_num)):\n",
        "    x = np.random.randint(x_crop//2, high=image.shape[0]- x_crop//2)\n",
        "    y = np.random.randint(y_crop // 2, high=label.shape[0] - y_crop // 2)\n",
        "    dst_image = image[x-x_crop//2 : x+x_crop//2, y-y_crop//2 : y+y_crop//2, :]\n",
        "    dst_label = label[x-x_crop//2 : x+x_crop//2, y-y_crop//2 : y+y_crop//2]\n",
        "\n",
        "    if np.random.random() > valid_ratio:\n",
        "        np.save(img_save_dir + '{}.npy'.format(i), dst_image)\n",
        "        np.save(target_save_dir + '{}.npy'.format(i), dst_label)\n",
        "        train_valid_count['train samples: '] += 1\n",
        "    else:\n",
        "        np.save(valid_img_save_dir + '{}.npy'.format(i), dst_image)\n",
        "        np.save(valid_target_save_dir + '{}.npy'.format(i), dst_label)\n",
        "        train_valid_count['valid samples: '] += 1\n",
        "\n",
        "print(train_valid_count)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fez41SYEl4zj",
        "outputId": "4ad71664-dbf3-4901-f4e3-5f2323409f33"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image.shape:  (2047, 2047, 4)\n",
            "label.shape:  (2047, 2047, 4) [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
            " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
            " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
            " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
            " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
            " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
            " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
            " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
            " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
            " 252 253 254 255]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 500/500 [00:40<00:00, 12.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'train samples: ': 397, 'valid samples: ': 103}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LandUseDataset(Dataset):\n",
        "    def __init__(self, imgs_dir, masks_dir):\n",
        "        self.imgs_dir = imgs_dir\n",
        "        self.masks_dir = masks_dir\n",
        "        self.ids = [splitext(file)[0] for file in listdir(imgs_dir)\n",
        "                    if not file.startswith('.')]\n",
        "\n",
        "    def preprocess(cls, img_nd):\n",
        "        img_trans = img_nd.transpose((2, 0, 1)) #(256,256,3) -> (3,256,256)\n",
        "        return img_trans\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ids)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        idx = self.ids[index]\n",
        "        mask_path = self.masks_dir + idx + '.npy'\n",
        "        img_path = self.imgs_dir + idx + '.npy'\n",
        "        img = np.load(img_path)\n",
        "        mask = np.load(mask_path)\n",
        "\n",
        "        img = self.preprocess(img)\n",
        "        img = img / 255\n",
        "\n",
        "        img = torch.from_numpy(img.copy())\n",
        "        mask = torch.from_numpy(mask.copy())\n",
        "\n",
        "        return img, mask\n",
        ""
      ],
      "metadata": {
        "id": "Tfm0xAh3Y20R"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class double_conv(nn.Module):\n",
        "    '''(conv => BN => ReLU) * 2'''\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(double_conv, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(inplace=True),  # modify the input directly, without allocating any additional output\n",
        "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(inplace=True))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "\n",
        "class inconv(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(inconv, self).__init__()\n",
        "        self.conv = double_conv(in_ch, out_ch)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "\n",
        "class down(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(down, self).__init__()\n",
        "        self.mpconv = nn.Sequential(\n",
        "            nn.MaxPool2d(2),\n",
        "            double_conv(in_ch, out_ch))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.mpconv(x)\n",
        "        return x\n",
        "\n",
        "class up(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(up, self).__init__()\n",
        "        self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "        self.conv = double_conv(in_ch, out_ch)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        x1 = self.up(x1)\n",
        "        x = torch.cat([x2, x1], dim=1) # batchsize, channel, h, w\n",
        "        #x2: (8,64,256,256),x1: (8,64,256,256) -> (8,128,256,256)\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "\n",
        "class outconv(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(outconv, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_ch, out_ch, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, n_channels, n_classes):\n",
        "        super(UNet, self).__init__()\n",
        "        self.inc = inconv(n_channels, 64)\n",
        "        self.down1 = down(64, 128)\n",
        "        self.down2 = down(128, 256)\n",
        "        self.down3 = down(256, 512)\n",
        "        self.down4 = down(512, 512)\n",
        "        self.up1 = up(1024, 256)\n",
        "        self.up2 = up(512, 128)\n",
        "        self.up3 = up(256, 64)\n",
        "        self.up4 = up(128, 64)\n",
        "        self.outc = outconv(64, n_classes)\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for module in self.modules():\n",
        "            if isinstance(module, nn.Conv2d) or isinstance(module, nn.Linear):\n",
        "                nn.init.kaiming_normal_(module.weight)\n",
        "                if module.bias is not None:\n",
        "                    module.bias.data.zero_()\n",
        "            elif isinstance(module, nn.BatchNorm2d):\n",
        "                module.weight.data.fill_(1)\n",
        "                module.bias.data.zero_()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.inc(x)\n",
        "        x2 = self.down1(x1)\n",
        "        x3 = self.down2(x2)\n",
        "        x4 = self.down3(x3)\n",
        "        x5 = self.down4(x4)\n",
        "        x = self.up1(x5, x4)\n",
        "        x = self.up2(x, x3)\n",
        "        x = self.up3(x, x2)\n",
        "        x = self.up4(x, x1)\n",
        "        x = self.outc(x)\n",
        "        return x\n",
        ""
      ],
      "metadata": {
        "id": "QWc__rW3ZHxU"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "input = torch.randn((8,3,256,256))\n",
        "net = UNet(n_channels=3, n_classes=4)\n",
        "y = net(input)\n",
        "print(y.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0TaUYJoZQ76",
        "outputId": "7cd27d66-998a-4327-ac23-8698cdc0c49e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 4, 256, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import argparse\n",
        "\n",
        "\n",
        "def get_unet_args():\n",
        "    parser = argparse.ArgumentParser(description='Train the UNet on images and target masks',\n",
        "                                     formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
        "    parser.add_argument('-e', '--epochs', metavar='E', type=int, default=21,\n",
        "                        help='Number of epochs', dest='epochs')\n",
        "    parser.add_argument('-b', '--batch-size', metavar='B', type=int, nargs='?', default=4,\n",
        "                        help='Batch size', dest='batchsize')\n",
        "    parser.add_argument('-l', '--learning-rate', metavar='LR', type=float, nargs='?', default=5e-4,\n",
        "                        help='Learning rate', dest='lr')\n",
        "    parser.add_argument('-f', '--load', dest='load', type=str, default=False,\n",
        "                        help='Load model from a .pth file')\n",
        "\n",
        "    return parser.parse_args()"
      ],
      "metadata": {
        "id": "IJ7NO4yRZVm9"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        ""
      ],
      "metadata": {
        "id": "ytM30yHeZbQE"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_net(net = UNet, device = torch.device('cuda'),\n",
        "              epochs=5, batch_size=1, lr=0.1, save_cp=True):\n",
        "\n",
        "    dir_checkpoint = dataset_path + \"ckpts/\"\n",
        "    os.makedirs(dir_checkpoint, exist_ok=True)\n",
        "\n",
        "    dataset_dir = \"/content/drive/My Drive/unet/resample/\"\n",
        "    # step 1\n",
        "    train_dir = dataset_dir + \"train/\"\n",
        "    valid_dir = dataset_dir + \"valid/\"\n",
        "\n",
        "\n",
        "    # step 2\n",
        "    train_data = LandUseDataset(imgs_dir = train_dir + 'src/', masks_dir = train_dir +'label/')\n",
        "    valid_data = LandUseDataset(imgs_dir = valid_dir + 'src/', masks_dir = valid_dir +'label/')\n",
        "\n",
        "    # step 3\n",
        "    train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True, num_workers= 4)\n",
        "    valid_loader = DataLoader(dataset=valid_data, batch_size=batch_size)\n",
        "\n",
        "    optimizer = optim.Adam(net.parameters(), lr, (0.9, 0.999))\n",
        "    criterion = nn.CrossEntropyLoss()  # BCELOSS (Binary Cross Entropy) for binary classification\n",
        "\n",
        "    train_acc_list = []\n",
        "    valid_acc_list = []\n",
        "    train_epoch = []\n",
        "    valid_epoch = []\n",
        "\n",
        "    for epoch in range(0, epochs):\n",
        "\n",
        "        # ---------------------------------------- train ----------------------------------------\n",
        "\n",
        "        net.train()\n",
        "        epoch_loss = 0\n",
        "        acc = 0\n",
        "        train_record = {'train_loss': 0, 'train_acc': 0}\n",
        "\n",
        "        for i, (imgs, true_masks) in enumerate(train_loader):\n",
        "            imgs = Variable(imgs).to(device=device, dtype=torch.float32)  # device: cpu?gpu?\n",
        "            true_masks = Variable(true_masks).to(device=device, dtype=torch.int64)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            masks_pred = net(imgs)\n",
        "            loss = criterion(masks_pred, true_masks)\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "            # Backprop + optimize\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # get acc\n",
        "            _, masks_pred_max = torch.max(masks_pred.data, 1)\n",
        "            corr = torch.sum(masks_pred_max == true_masks.detach())\n",
        "            tensor_size = masks_pred_max.size(0) * masks_pred_max.size(1) * masks_pred_max.size(2)\n",
        "            acc += float(corr) / float(tensor_size)\n",
        "            batch_acc = acc/(i+1)\n",
        "\n",
        "            train_record['train_loss'] += loss.item()\n",
        "            train_record['train_acc'] += batch_acc\n",
        "\n",
        "            if i % (2 * batch_size) == 0:\n",
        "                print('Epoch [{} / {}], batch: {}, train loss: {}, train acc: {}'.format(epoch+1,epochs, i+1, loss.item(), batch_acc))\n",
        "\n",
        "        train_record['train_loss'] = train_record['train_loss'] / len(train_loader)\n",
        "        train_record['train_acc'] = train_record['train_acc'] / len(train_loader)\n",
        "\n",
        "        train_acc_list.append(train_record['train_acc'])\n",
        "        train_epoch.append(epoch+1)\n",
        "\n",
        "        print(train_record)\n",
        "\n",
        "        # ===================================== Validation ====================================#\n",
        "        net.eval()\n",
        "\n",
        "        val_acc = 0\n",
        "        val_record = {'val_loss': 0, 'val_acc': 0}\n",
        "\n",
        "        for i, (imgs, true_masks) in enumerate(valid_loader):\n",
        "            imgs = imgs.to(device=device, dtype=torch.float32)\n",
        "            val_masks = true_masks.to(device=device, dtype=torch.int64)\n",
        "            val_pred = net(imgs)\n",
        "            val_loss = criterion(val_pred, val_masks)\n",
        "\n",
        "            _, val_pred_max = torch.max(val_pred.data, 1)\n",
        "            corr = torch.sum(val_pred_max == val_masks.detach())\n",
        "            tensor_size = val_pred_max.size(0) * val_pred_max.size(1) * val_pred_max.size(2)\n",
        "            val_acc += float(corr) / float(tensor_size)\n",
        "            val_batch_acc = val_acc / (i + 1)\n",
        "\n",
        "            val_record['val_loss'] += val_loss.item()\n",
        "            val_record['val_acc'] += val_batch_acc\n",
        "\n",
        "        val_record['val_loss'] = val_record['val_loss'] / len(valid_loader)\n",
        "        val_record['val_acc'] = val_record['val_acc'] / len(valid_loader)\n",
        "\n",
        "        valid_acc_list.append(val_record['val_acc'])\n",
        "        valid_epoch.append(epoch + 1)\n",
        "\n",
        "        print(val_record)\n",
        "        print('----------------------------------------------------------------------------------------------------')\n",
        "\n",
        "        if save_cp:\n",
        "            os.makedirs(dir_checkpoint, exist_ok=True)\n",
        "            if epoch % 5 == 0:\n",
        "                torch.save(net.state_dict(), dir_checkpoint + f'CP_epoch{epoch}.pth')\n",
        "\n",
        "    #----------------------------------------- plot acc curves -------------------------------------------------------\n",
        "    plt.plot(train_epoch, train_acc_list, label = \"train acc\")\n",
        "    plt.plot(valid_epoch, valid_acc_list, label=\"valid acc\")\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('acc')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "qL3W7NeGZd3i"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# 假设 output 是模型的输出张量，target 是目标张量\n",
        "output = torch.randn(2, 5, 64, 64)  # 假设输出为(batch_size=2, num_classes=5, height=64, width=64)\n",
        "target = torch.randint(0, 5, (2, 64, 64))  # 假设目标为(batch_size=2, height=64, width=64)\n",
        "\n",
        "# 检查输出和目标的形状\n",
        "print(\"Output shape:\", output.shape)\n",
        "print(\"Target shape:\", target.shape)\n",
        "\n",
        "# 调整目标张量的维度以匹配输出的维度\n",
        "target = target.unsqueeze(1)  # 在第二个维度（索引为1）上增加一个维度\n",
        "print(\"Adjusted target shape:\", target.shape)\n",
        "\n",
        "# 现在，output 和 target 的形状应该是一致的，可以进行交叉熵计算\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hT_-pW2elitg",
        "outputId": "bac9f41e-58ed-44fa-ed05-805400e51829"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output shape: torch.Size([2, 5, 64, 64])\n",
            "Target shape: torch.Size([2, 64, 64])\n",
            "Adjusted target shape: torch.Size([2, 1, 64, 64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "# 定义输入和输出文件夹路径\n",
        "input_folder = '/content/drive/My Drive/unet/ori_data/'\n",
        "output_folder = '/content/drive/My Drive/unet/ori_data/'\n",
        "\n",
        "# 确保输出文件夹存在\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# 遍历输入文件夹中的所有文件\n",
        "for filename in os.listdir(input_folder):\n",
        "    # 检查文件是否为PNG格式\n",
        "    if filename.endswith('.png'):\n",
        "        # 打开PNG图像\n",
        "        png_image = Image.open(os.path.join(input_folder, filename))\n",
        "\n",
        "        # 构造输出文件路径并将PNG图像转换为TIFF格式\n",
        "        output_path = os.path.join(output_folder, os.path.splitext(filename)[0] + '.tiff')\n",
        "        png_image.save(output_path)\n"
      ],
      "metadata": {
        "id": "KlvUnBR6mpIz"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "\n",
        "net = UNet(n_channels= 3, n_classes=5)\n",
        "net.to(device)\n",
        "\n",
        "args = get_unet_args()\n",
        "train_net(net=net,epochs=args.epochs,batch_size=args.batchsize,lr=args.lr,device=device,save_cp= True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "eoHsRk9BZnv4",
        "outputId": "c5beca3c-e878-4b47-84b3-0675f27f83fb"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Given groups=1, weight of size [64, 3, 3, 3], expected input[4, 4, 256, 256] to have 3 channels, but got 4 channels instead",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-d2d84e69a25e>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_unet_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtrain_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msave_cp\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-15-98c7de2b508c>\u001b[0m in \u001b[0;36mtrain_net\u001b[0;34m(net, device, epochs, batch_size, lr, save_cp)\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mmasks_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasks_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-cf916420fe56>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdown1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mx3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdown2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-cf916420fe56>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-cf916420fe56>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    454\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 456\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    457\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [64, 3, 3, 3], expected input[4, 4, 256, 256] to have 3 channels, but got 4 channels instead"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def color_annotation(image):\n",
        "    color = np.ones([image.shape[0], image.shape[1], 3])\n",
        "    color[image == 0] = [0, 0, 0]  # bg\n",
        "    color[image == 1] = [204, 104, 0]  # water\n",
        "    color[image == 2] = [0, 153, 0]  # vegatation\n",
        "    color[image == 3] = [102, 0, 204]  # urban extent\n",
        "    return color"
      ],
      "metadata": {
        "id": "segg954hgVSG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def predict_img(net, img, device = torch.device('cuda')):\n",
        "    net.eval()\n",
        "    img = img.transpose((2, 0, 1))\n",
        "    img = img / 255\n",
        "    img = torch.from_numpy(img)\n",
        "    img = img.unsqueeze(0) # add batch dimention\n",
        "    img = img.to(device=device, dtype=torch.float32)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = net(img)\n",
        "        probs = F.softmax(output, dim=1)\n",
        "        probs = torch.max(probs.squeeze(0), dim=0) # torch.max returns a tuple (max_values, indices)\n",
        "        predict = probs[1].cpu().numpy()\n",
        "\n",
        "    return predict"
      ],
      "metadata": {
        "id": "h7gb8v74gWpZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_subsample_centroids(img, img_size=256):\n",
        "    h_total = img.shape[0]\n",
        "    w_total = img.shape[1]\n",
        "    h_step = int(h_total // img_size * 2)\n",
        "    w_step = int(w_total // img_size * 2)\n",
        "    x_list = np.linspace(img_size//2, h_total-img_size//2, num=h_step)\n",
        "    y_list = np.linspace(img_size//2, w_total -img_size//2, num=w_step)\n",
        "\n",
        "    new_x_list = []\n",
        "    new_y_list = []\n",
        "\n",
        "    for i in x_list:\n",
        "        for j in y_list:\n",
        "            new_x_list.append(int(i))\n",
        "            new_y_list.append(int(j))\n",
        "\n",
        "    return zip(new_x_list, new_y_list)"
      ],
      "metadata": {
        "id": "UCO5vcVVgY19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "dir_checkpoint = dataset_path + \"ckpts/\"\n",
        "model_name = 'CP_epoch20.pth'\n",
        "file_name = dataset_path + 'ori_data/img.npy'\n",
        "save_dir = dataset_path + 'dst/'\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "out_path = save_dir + 'predict.png'\n",
        "\n",
        "net = UNet(n_channels=3, n_classes=4)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "net.to(device=device)\n",
        "net.load_state_dict(torch.load(dir_checkpoint + model_name, map_location=device))\n",
        "\n",
        "img = np.load(file_name)\n",
        "print(img.shape)\n",
        "\n",
        "subsample_size = 256\n",
        "x_y_list = get_subsample_centroids(img, img_size=subsample_size)\n",
        "\n",
        "sub_imgs = []\n",
        "for x,y in x_y_list:\n",
        "    sub_img = img[x - subsample_size//2: x + subsample_size//2,\n",
        "              y - subsample_size//2 : y + subsample_size//2, :]\n",
        "    sub_imgs.append(sub_img)\n",
        "\n",
        "predict_list = []\n",
        "for sm in sub_imgs:\n",
        "    predict = predict_img(net=net, img=sm, device=device)\n",
        "    predict =np.squeeze(predict)  # remove batch dimention\n",
        "    predict_list.append(predict)\n",
        "\n",
        "msk = np.zeros((img.shape[0], img.shape[1]))\n",
        "\n",
        "x_y_list = get_subsample_centroids(img, img_size=subsample_size)\n",
        "\n",
        "crop_size = subsample_size // 2\n",
        "# crop_size = 100\n",
        "\n",
        "for i, (x, y) in enumerate(x_y_list):\n",
        "    msk[x - crop_size: x + crop_size, y - crop_size : y + crop_size] = predict_list[i]#[28:256-28,28:256-28]\n",
        "\n",
        "predict_image = color_annotation(msk).astype(np.uint8)\n",
        "cv2.imwrite(out_path, predict_image)\n",
        ""
      ],
      "metadata": {
        "id": "13y5y4-9gb71"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}